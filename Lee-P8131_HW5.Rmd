---
title: "P8131 HW5"
author: "Brian Jo Hsuan Lee"
date: "3/15/2022"
output: pdf_document
---

Load packages
```{r, message=F}
library(tidyverse)
library(pscl)
```

## Problem 1: Crab Satellite Count

Import and tidy data

```{r, warning=F, message=F}
# txt file read in using read_delim(), separated grouped values, and corrected column types
crab_data = 
  read_delim("HW5-crab.txt", delim = "\t") %>% 
  mutate(
    number = str_trim(number, side = c("both"))
  ) %>% 
  separate(number, c("number", "C", "S", "W", "Wt", "Sa"), sep = " +") %>% 
  mutate(
    across(where(is.character), as.numeric)
  )
```

a) 
**Fit a simple Poisson model, check the goodness of fit and interpret the model**

```{r}
# m1 model fit
crab_m1 = glm(Sa ~ W, family = poisson, data = crab_data)
summary(crab_m1)

# both deviance residual and pearson's residual goodness of fit tests, 
# with df = 173 observations - 2 predictors = 171
crab_m1_deviance_pval = 1 - pchisq(crab_m1$deviance, 171)
crab_m1_pchisq = sum(residuals(crab_m1, 'pearson')^2)
crab_m1_pchisq_pval = 1 - pchisq(crab_m1_pchisq, 171)

ifelse(crab_m1_deviance_pval > 0.05 | crab_m1_pchisq_pval > 0.05, 
       'Failed to reject the null, since no significant evidence suggest the poisson fit is not good',
       'Reject the null with significant data suggesting the poisson fit is not good')
```

Fit M1 shows the log count of a female horseshoe crab's satellite increases by 0.164 per unit increase of its carapace width. The coefficient for carapace width is significant at p-value < 2e-16, despite the simple poisson model does not provide a good fit to the data.

b) 
**Fit a Poisson model with 2 predictors, compare it with the previous model and interpret it**

```{r}
# m2 model fit
crab_m2 = glm(Sa ~ W + Wt, family = poisson, data = crab_data)
summary(crab_m2)
```

```{r, eval=F, echo=F}
# if we wish to consider the interaction term of width and weight, the following model explores that collection of predictors
# m3 model fit, including an additional interaction term
crab_m3 = glm(Sa ~ W * Wt, family = poisson, data = crab_data)
summary(crab_m3)

# use chisq test to run deviance analysis on the nested models m2 and m3,
# with df = 170 m2 predictors - 169 m3 predictors = 1
m2_m3_stat = crab_m2$deviance - crab_m3$deviance
m2_m3_pval = 1 - pchisq(m2_m3_stat, df = 170-169)
ifelse(m2_m3_pval > 0.05, 
       'Failed to reject the null since no significant evidence suggest M3 has a better fit',
       'Reject the null with significant evidence suggesting the M3 model fits the data better')
# we learn that the model including the interaction term yields highly significant coefficients and provides a better fit
```

```{r, eval=F, echo=F}
# if we wish to evaluate the goodness of fit m2 and m3, see analysis as follows
# both deviance residual and pearson's residual goodness of fit tests, 
# with df = 173 observations - 3 predictors = 170
crab_m2_deviance_pval = 1 - pchisq(crab_m2$deviance, 170)
crab_m2_pchisq = sum(residuals(crab_m2, 'pearson')^2)
crab_m2_pchisq_pval = 1 - pchisq(crab_m2_pchisq, 170)

ifelse(crab_m2_deviance_pval > 0.05 | crab_m2_pchisq_pval > 0.05, 
       'Failed to reject the null, since no significant evidence suggest the poisson fit is not good',
       'Reject the null with significant data suggesting the poisson fit is not good')

# both deviance residual and pearson's residual goodness of fit tests, 
# with df = 173 observations - 4 predictors = 169
crab_m3_deviance_pval = 1 - pchisq(crab_m3$deviance, 169)
crab_m3_pchisq = sum(residuals(crab_m3, 'pearson')^2)
crab_m3_pchisq_pval = 1 - pchisq(crab_m3_pchisq, 169)

ifelse(crab_m3_deviance_pval > 0.05 | crab_m3_pchisq_pval > 0.05, 
       'Failed to reject the null, since no significant evidence suggest the poisson fit is not good',
       'Reject the null with significant data suggesting the poisson fit is not good')

# we learn that either model does not fit the data well...
```

Fit M2 shows the log count of a female horseshoe crab's satellite increases by 0.0459 per unit increase of its carapace width while adjusting for its weight, and it increases by 0.447 per unit increase of its weight, holding carapace width fixed. Only the weight predictor is significant.

```{r}
# use chisq test and evaluate the nested models m1 and m2,
# with df = 171 m1 predictors - 170 m2 predictors = 1
m1_m2_stat = crab_m1$deviance - crab_m2$deviance
m1_m2_pval = 1 - pchisq(m1_m2_stat, df = 171-170)
ifelse(m1_m2_pval > 0.05, 
       'Failed to reject the null, since no significant evidence suggest the larger model has a better fit',
       'Reject the null with significant evidence suggesting the larger model fits the data better')
```

Per the results of the deviance analysis, M2 has a significantly better fit and is preferred to M1. Likewise, M2 also has a lower AIC than M1, suggesting its better fit.

c)
**Estimate overdispersion and interpret under the assumption of overdispersion**

```{r}
# obtain dispersion paramater using m3's pearson's chisq residual
# with df = 173 observations - 3 predictors = 170
crab_m2_pchisq = sum(residuals(crab_m2, 'pearson')^2)
phi = crab_m2_pchisq/170; phi
# the following code yields a similar phi estimate
## alt_phi = crab_m2$deviance/crab_m2$df.residual; alt_phi
```

For count models, overdispersion occurs when $Var[X] > E[X] = \lambda$, and it is shown with $\phi = 3.16 > 1$. 

```{r}
summary(crab_m2, dispersion = phi)
```

```{r}
res = residuals(crab_m2, type='pearson')
plot(qnorm((173+1:173+0.5)/(2*173+1.125)),
     sort(abs(res)),
     xlab='Expected Half-Normal Order Stats',
     ylab='Ordered Abs Pearson Residuals')
abline(a=0, b=1)
abline(a=0, b=sqrt(phi), lty=2)
```

The estimated intercept and coefficients for the new fit are equivalent to those of the original fit, as shown in the summaries, and therefore have the same interpretation as for the original fit. The half-normal plot visualizes $\phi > 1$ by displaying the data deviance (linear regression as the dashed line) from the solid $x = y$ reference line in a $\phi^{-1}(\frac{n+i+0.5}{2n+1.125})$ vs $|r_{(i)}|$ plot, where $r$ is Pearson's residuals. It shows that the dispersion is not constant and the dashed line does not truly capture the trend. 

```{r, eval=F, echo=F}
# if we were to evaluate m2 against m1 under the assumption that there is overdispersion, see the following code for deviance analysis
# with df = 171 m1 predictors - 170 m2 predictors = 1
f_stat = m1_m2_stat/((171-170)*phi)
m1_m2_phi_pval = 1 - pf(f_stat, (171-170), 170); m1_m2_phi_pval

# we see that there's no significant evidence to reject the null and we should go with the smaller model if overdispersion is assumed
```

## Problem 2: Fish Parasite Count

```{r, warning=F, message=F}
# txt file read in using read_delim() and dropped 'NA' rows and o 'omit' columns
para_data = 
  read_delim("HW5-parasite.txt", delim = "\t") %>% 
  dplyr::select(c('Intensity', 'Year', 'Length', 'Area')) %>% 
  mutate(
    Year = factor(Year),
    Area = factor(Area)
  ) %>% 
  drop_na()
```

a) 
**Fit a simple Poisson model, check the goodness of fit and interpret the model**

```{r}
# m1 model fit
para_m1 = glm(Intensity ~ Year + Area + Length, family = poisson, data = para_data)
summary(para_m1)
```

The fit shows the log count of parasites is 2.64 in year 1999, in area 1 and at fish length 0. The count increases by $e^{0.670} = 1.95$ times of year 1999 in 2000, but is $e^{-0.218} = 0.804$ times of year 1999 in 2001 while adjusting for area and body length; the count response is $e^{-0.212} = .809$ and $e^{-0.117} = 0.890$ times of area 1 in area 2 and area 3, respectively, and $e^{-0.140} = 4.06$ times area 1 in area 4 while adjusting for year and body length; the count increases by $1-e^{0.0284} = 0.03$ in percentage per unit increase in length while adjusting for year and area. The predictors, including the intercept and all coefficients, are significant at $\alpha = 0.05$.

b) 
**Goodness of fit and conclusions**

```{r}
# both deviance residual and pearson's residual goodness of fit tests, 
# with df = 1191 observations -  7 predictors = 1184
para_m1_deviance_pval = 1 - pchisq(para_m1$deviance, 1184)
para_m1_pchisq = sum(residuals(para_m1, 'pearson')^2)
para_m1_pchisq_pval = 1 - pchisq(para_m1_pchisq, 1184)

ifelse(para_m1_deviance_pval > 0.05 | para_m1_pchisq_pval > 0.05, 
       'Failed to reject the null, since no significant evidence suggest the poisson fit is not good',
       'Reject the null with significant data suggesting the poisson fit is not good')
```

Though the coefficients are significant, it is a poor fitting model for the data. We may speculate the issue to be that the data actually falls in a zero-inflated, zero-truncated, or multi-modal poisson distribution, and question if the overdispersion paramter equals 1. 

c)
**Fit a zero-inflated poisson model and interpret it**

```{r}
# m2 model fit
para_m2 = zeroinfl(Intensity ~ Year + Length | Area, data = para_data)
summary(para_m2)
```

Assuming fish in different areas may exhibit a difference in their susceptibility to parasites, and the parasite intensity depends on year and body length, fit M2 is hence created. The model first evaluates whether a fish could be susceptible to parasite infection under a binomial distribution depending on the area, and then models the parasite count under a poison distribution. Contextually speaking, in areas 2, 3, and 4, the respective odds of a fish is susceptible to parasite infection is $e^{0.747} = 2.11$, $e^{0.681} = 1.96$, and $e^{-0.883} = 0.414$ times that of fish in area 1. If a fish is susceptible to infection in the eyes of the model, the parasite count on a fish in year 2000 and 2001 is $e^{0.421} = 1.52$ and $e^{0.099} = 1.10$ times a fish in year 1999, respectively, holding body length fixed. When adjusting for the year, a fish with an increased unit body length has $1-e^{-0.0439} = 0.957$ times the parasite count. 
